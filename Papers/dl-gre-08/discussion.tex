\section{Discussion} \label{sec:discussion}

We will now describe two experiments evaluating different aspects of
the performance of our algorithm. First, we will look at its running
time on randomly generated domain graphs of different sizes. Second,
we will compare the output of our algorithm to human-generated
descriptions.



\subsection{Quality of Output}

To compare the descriptions generated by our algorithm to
those humans produce, we use a corpus of
human-generated referring expressions collected and made available by
Jette Viethen and Robert
Dale\footnote{http://www.ics.mq.edu.au/~jviethen/drawers}.  The data
was collected in an experiment where participants were asked to
describe one of 16 filing cabinet drawers. The drawers had different
colors and were arranged in a four-by-four grid, as shown in Figure
\ref{fig:drawers}. The human-generated descriptions use four
non-relational properties (the drawer's \textsf{color}, its \textsf{column} and
\textsf{row} number, and whether it is in a \textsf{corner}) and five
relational properties (\textsf{above, below, next to, left of, right
of}). Of the 118 referring expressions, only 15 use relational properties.
Viethen and Dale \shortcite{viethen06:_algor_for_gener_refer_expres}
describe the data in more detail and present results of evaluating the
Full Brevity algorithm by \cite{}, the Incremental Algorithm by
\cite{} and the relational algorithm by \cite{} on this corpus.

\begin{figure}
\includegraphics[width=0.4\textwidth]{drawers}
\caption{A schematic view of the filing cabinets.\todo{needs nicer pic}}\label{fig:drawers}
\end{figure}


As described above \todo{needs to be described}, Dale and Reiter's
Incremental Algorithm is a special case of our algorithm, where no
roles are used and a specific order is imposed on the predicates. We
replicated Viethen and Dale's experiment, which tested the Incremental
Algorithm on the drawer domain with all possible preference ordering
given the four predicates
\textsf{color, column, row}, and \textsf{corner}
\cite{viethen06:_algor_for_gener_refer_expres}.  Unsurprisingly, we
get the same results as they did: 98 of the 103 non-relational
descriptions produced by humans can be generated using one of the 24
possible preference orderings. Unfortunately, there isn't one ordering
that covers all those 98 descriptions - a set of four different
orderings is necessary.



\newcite{viethen06:_algor_for_gener_refer_expres} also tested Dale and
Haddock's \shortcite{dale91:_gener_refer_expres_invol_relat}
Relational Algorithm on the drawer domain. Surprisingly, it could not
generate \textit{any} of the descriptions produced by humans. To
evaluate our algorithm's use of relations, we tested it on a
representation of the domain using the predicates \textsf{color} and
\textsf{corner} and the roles \textsf{above, below, next to, left of},
and \textsf{right of}. We did not include the \textsf{column} and
\textsf{row} predicates because every drawer can be uniquely
identified through those predicates. Since our algorithm has to
consider predicates before relations, this would mean that no relation
ever gets used. Like for the Incremental Algorithm, we tested all
possible orderings of predicates and roles (with the restriction that
all predicates come before all roles). For 10 of the 15 human-produced
relational descriptions there is an ordering such that using this
ordering our algorithm can generate this description. Figure
\ref{fig:example_outputs} shows the output of our \el\ algorithm for
one preference ordering of predicates. To cover 10 of the 15
human-produced descriptions three different orderings are
necessary. Of the five human-produced escriptions that the \el\
algorithm can not generate, two mention column information, which we
excluded from our domain, and three (which interestingly were all
produced by the same person) are of the format \textit{the
blue/pink/yellow/orange drawer above/below/next to/right of/left of
the two blue/pink/yellow/orange drawers}. This would correspond to the
following output from our algorithm: $C_1 \& \exists R . (C_2 \&
\exists R . C_2)$ (where $C_i$ are color predicates and $R$ a
role). While our algorithm does not generate descriptions that contain
the same relation on two levels of embedding for these drawers, it
does generate some other, simpler descriptions for them; for example,
$\textsf{orange} \& \exists
\textsf{left\_of} . (\textsf{pink}
\& \textsf{corner})$ which could be rendered as
\textit{the orange drawer left of the pink one in the corner}, or
$\textsf{orange} \& \exists \textsf{below} . \textsf{yellow}$,
which could be rendered as \textit{the orange drawer below the yellow
drawer}.

\todo{should we show some more examples? - ak}


\begin{figure*}

\begin{small}
\begin{tabular}{|lp{0.5\textwidth}p{0.4\textwidth}|}\hline
drawer & human-produce description & output of the \el\ algorithm\\\hline
2 & \textit{the orange drawer above the blue drawer} & $\exists \textsf{above}.(\textsf{blue}) \& \textsf{orange}$\\
4 & \textit{the yellow drawer on the top of the pink one} & $\exists \textsf{above}.(\textsf{pink}) \& \textsf{yellow}$\\
5 & \textit{the pink drawer in the fourth column below the yellow one} & $\exists \textsf{above}.(\textsf{orange}) \& \textsf{pink}$\\
6 & \textit{the yellow drawer on top of the yellow drawer} & $\exists \textsf{above}.(\textsf{yellow}) \& \textsf{yellow}$\\
6 & \textit{the yellow drawer that's above another yellow drawer} & \\
6 & \textit{the drawer after the two blue ones in horizontal sequence} & \\
7 & \textit{the blue drawer below the orange drawer in the second column} & $\exists \textsf{next}.(\exists \textsf{above}.(\textsf{orange}) \& \textsf{blue}) \& \exists \textsf{above}.(\textsf{blue}) \& \textsf{blue}$\\
7 & \textit{the blue drawer below the orange one} & \\
10 & \textit{the blue drawer above the pink drawer} & $\exists \textsf{above}.(\textsf{pink}) \& \textsf{blue}$\\
10 & \textit{the blue drawer above the pink drawer} & \\
11 & \textit{the yellow drawer next to the orange drawer} & $\exists \textsf{above}.(\textsf{orange}) \& \textsf{yellow}$\\
11 & \textit{the yellow one next to the orange one} & \\
12 & \textit{the orange drawer below the pink drawer} & $\exists \textsf{above}.(\textsf{pink} \& \textsf{corner}) \& \textsf{orange}$\\
14 & \textit{the orange drawer below the two yellow drawers} & $\exists \textsf{next}.(\textsf{pink} \& \textsf{corner}) \& \exists \textsf{next}.(\textsf{pink}) \& \textsf{orange}$\\
14 & \textit{the orange drawer below the two yellow drawers} & \\\hline
\end{tabular}
\end{small}

\caption{Human produced descriptions and output of our \el\  algorithm using the ordering \textsf{corner}, \textsf{color}, \textsf{above, next, below, right, left}}
\label{fig:example_outputs}
\end{figure*}

% ordering no. 235
%List(corner, green, pink, orange, blue)
%List(above, next, below, right, left)




\subsection{Efficiency}

Both the \el\ and the \alc\ algorithms took about 15 milliseconds to
compute distinguishing concepts for all 16 individuals in the Viethen
\& Dale dataset.\footnote{We measured all runtimes on a MacBook Pro
  (Intel Core 2 Duo, 2.16 GHz) running Java 1.6 beta, and allowed the
  Java VM to warm up, i.e.\ just-in-time compile all bytecode, before
  taking the measurements.}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{runtimes}
  \caption{Average runtimes (in ms) of the two algorithms on random
    models of     different sizes.} 
  \label{fig:runtimes}
\end{figure}

In order to get a more comprehensive picture of the algorithms'
efficiency, we ran them on random models with increasing numbers of
individuals.  Each model had random interpretations for ten different
propositional and four relational symbols; each individual had a 10\%
chance to be in the extension of each propositional symbol, and each
pair of individuals had a 10\% chance to be related by a relational
symbol.  The results (averaged over 10 runs for each model size) are
shown in Fig.~\ref{fig:runtimes}.  As the figure shows, the \el\
algorithm takes about 350 ms on average to generate relational REs for
all individuals in the model of size 100, i.e.\ less than 4 ms on
average for each individual.  The \alc\ algorithm is even faster, at
about 140 ms for the model of size 100.  As far as we know, these are
by far the fastest published runtimes for any relational GRE algorithm
in the literature.

Another encouraging aspect of both runtime graphs is that they seem to
be approximated well by quadratic functions.  So although the
worst-case runtime of the \el\ algorithm might be exponential, both
algorithms empirically exhibit (low) polynomial runtime on the inputs
we considered.



\subsection{Interface to realization}

%\begin{itemize}
%\item there's a risk to generate a concept that can't be realized,
%  especially for the \alc\ algorithm
%\item everybody except perhaps SPUD has this problem
%\item problem is worse in our case because it is harder to control the
%  order in which atoms and relations are explored
%\item would be interesting for future work to think about how
%  search in the bisim algorithms can be controlled by the realizer
%\end{itemize}

Our GRE algorithms do not guarantee that the concepts they compute can
actually be realized in language.  For example, none of the concepts
our algorithms computed in the Viethen \& Dale domain contained an
atom that would commonly be realized as a noun; the property
$\mathsf{drawer}$ is never used because it applies to all individuals
in the domain.  This particular problem could easily be worked around
in a post-processing step.  However, another problem arises from the
massive use of negation in the \alc\ algorithm; it will be hard for
any realizer to find a reasonable way of expressing the concept $\neg
\exists R.(\neg P \sqcap \neg Q)$ from the example in
Fig.~\ref{fig:el-vs-alc} as a smooth noun phrase.  Although we agree
with \newcite{deemter01:_gener_refer_expres} and others that the
careful use of negation and disjunction can improve REs, these
connectives must not be overused.  Thus we consider the concepts
computed by the \el\ algorithm ``safer'' with respect to realization.

Of course, we share the problem of interfacing GRE and realization
with every other approach that separates these two modules, i.e.\
almost the entire GRE literature (notable exceptions are e.g.\ SPUD
\cite{Stone2003a} and \newcite{Horacek1997}).  In principle, we
believe that it is a good idea to handle sentence planning and
realization in a single module; for instance, SPUD can use its
awareness of the syntactic context to generate succinct REs as in
``take the rabbit from the hat''.  We hope that the ideas we have
explored here for efficient and expressive RE generation can
eventually be combined with recent efficient algorithms for integrated
sentence planning and realization, such as in \newcite{KolSto07}.

One problem that arises in our approach specifically is that the
bisimulation classes algorithms derive some measure of efficiency from
their freedom to build concepts without having to respect any
linguistic constraints.  It seems straightforward to extend Krahmer et
al.'s \shortcite{Krahmer2003} approach such that it only considers
subgraphs that can actually be realized, because their algorithm
proceeds by a genuine search for uniquely identifying subgraphs, and
will simply take a different branch of the search if some subgraph is
useless.  Our algorithms don't search in the same way; any constraints
that disallow certain refinements of a partition jeopardize the
algorithms' ability to find a partition into singletons in polynomial
time.  A particularly vivid example is the fact that both algorithms
crucially split over all propositional symbols before they start
iterating over relational symbols; changing this may make them
incomplete.  Investigating this interplay between efficiency and
linguistic constraints is an interesting avenue for future research.




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "dl-gre-08"
%%% End: 
