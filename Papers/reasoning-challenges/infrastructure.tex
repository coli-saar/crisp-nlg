\section{Infrastructure}
\label{sec:infrastructure}

\textbf{[RP: Talk a little bit about the current planning competition and (online)
competitions from other research areas (GIVE, CP?, others?)... Outline the
infrastructure we're proposing. We need some references here...]}

There are three groups of people involved in a competition: the organisers, the participants, and the audience (which usually includes organisers and participants). In the following, we outline an infrastructure that makes competitions easier to run and more valuable for each of these groups.

\begin{itemize}
  \item Organisers benefit from a mostly automated platform that is maintained by the community, which should greatly reduce the effort needed to run a competition.
  \item Participants benefit from a well-defined environment for running their systems, short feedback times after submitting a system, and a standardised test and benchmark platform for experimenting with novel algorithms.
  \item The audience, i.e., the scientific community, benefits from the improved discussion and report facilities. The scientific value of competitions is to find out \emph{why} a system shows a certain performance, not only \emph{that} it does.
\end{itemize}

We want to stress that the proposed platform is not limited to the domain of planning problems. Therefore, we will talk about \emph{problem classes} and \emph{instances} in the following, instead of planning domains and problems.

\subsection{Submitting Systems}

A system is uploaded as an archive containing
\begin{itemize}
  \item A specification of the input format type
  \item An executable file
  \item Optional format conversion rules
  \item Optional other files necessary for running the system
\end{itemize}

The environment in which the system will be run is available as a virtual machine image, such that participants can compile and test their systems before uploading them.

To upload a system, the participants have to register with the maintainer. We hope that this sets the bar high enough to avoid the submission of malicious systems.

\subsection{Submitting Instances}

There are three levels at which instances are submitted: the problem class, the instance, and the \emph{data}. The problem class groups similar instances (for example those from the same planning domain), and possibly data describing the class (such as a PDDL planning domain). The instance itself may contain a human-readable description and several sets of data. Each set of data has a \emph{type}, which determines what systems the data is suitable for (e.g.\ different subsets of PDDL, or EUROPA). All sets of data for one instance should of course model the same problem.

Problem classes, instances, and data can be submitted by any registered user. In order to avoid abuse, the number of instances should be limited (e.g.\ per hour), and a simple validity check should be possible (such as running a parser if the format is PDDL).

\subsection{Running Systems}

Let us now come to the backend of the platform. Its main task is to prepare the data for the different systems, to distribute the work of running the systems among a number of (identical) machines, and to collect the results in a central database.

Systems will be run in a sandbox environment with well-defined resource limits such as number of processors, available memory and processor time, and limited disk space and network connectivity.

The platform provides automatic conversion between different formats. When new instance data is submitted, it is automatically converted into all formats for which conversions are available. Then it is scheduled to be run on all suitable systems.

When a system is updated or a new system is submitted, all suitable instances are scheduled to be run on the system.

A number of statistics is gathered during execution. The obvious statistics would be runtime, memory consumption, and whether the system could solve the problem. More detailed statistics will require system-specific support.

\subsection{Reports and Discussion}

The public interface of the competition platform serves two main purposes: \emph{interactivity}, which lets users describe and discuss systems and problems, and \emph{reporting}, which presents the results of running the systems.

We propose to achieve interactivity by making use of three standard technologies:
\begin{itemize}
  \item a \emph{wiki} for all the descriptive content,
  \item a \emph{discussion board} for each wiki page (similar to the discussion feature in Wikipedia), and
  \item a \emph{tagging} system, which allows arbitrary grouping of systems and problems.
\end{itemize}

The reporting engine connects to the central database that is populated by the backend. Reports can be embedded into wiki pages and customised using tags. For example, a user can create a page with the report comparing the runtimes of three systems, \emph{A}, \emph{B}, and \emph{C}, on all instances labeled \emph{mediumHard}.
