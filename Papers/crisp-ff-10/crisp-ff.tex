




\section{FF Pitfalls and Fixes}
\label{sec:crisp-ff}




It turns out that, as far as the suitability of commonly used
pre-processing and search techniques are concerned, sentence
generation diverges significantly from most known benchmark
domains. We examine this here, in detail, for the case of FF
\cite{HoffmannNebel01}. We show how certain hitherto irrelevant
details of the pre-processing suddenly become deadly obstacles to
performance, and how certain widely used search techniques -- namely
goal orderings and the relaxed plan heuristic -- are completely off
the mark and partly even detrimental. For some of the observed
pitfalls, we are able to provide simple fixes; others pose serious
challenges to planning research. We focus first on the pre-processing,
then on the search techniques.













\subsection{Pre-Processing}
\label{sec:crisp-ff:preprocess}



%../ff -o xtag-3-2-domain.lisp -f xtag-3-2-problem.lisp -T -H: 0.10
%../ff -o xtag-3-2-domain.lisp -f xtag-3-2-problem.lisp -T: 1.54
%../ff -o xtag-3-2-domain.lisp -f xtag-3-2-problem.lisp -H: 0.30
%../ff -o xtag-3-2-domain.lisp -f xtag-3-2-problem.lisp: 1.80


%../ff -o xtag-5-2-domain.lisp -f xtag-5-2-problem.lisp -T -H: 0.29
%../ff -o xtag-5-2-domain.lisp -f xtag-5-2-problem.lisp -T: seg fault ie too much memory
%../ff -o xtag-5-2-domain.lisp -f xtag-5-2-problem.lisp -H: 11.08
%../ff -o xtag-5-2-domain.lisp -f xtag-5-2-problem.lisp: seg fault ie too much memory


%../ff -o xtag-3-3-domain.lisp -f xtag-3-3-problem.lisp -T -H: 
%../ff -o xtag-3-3-domain.lisp -f xtag-3-3-problem.lisp -T: seg fault ie too much memory
%../ff -o xtag-3-3-domain.lisp -f xtag-3-3-problem.lisp -H: 
%../ff -o xtag-3-3-domain.lisp -f xtag-3-3-problem.lisp: seg fault ie too much memory








FF's pre-process contains two details that, for a long time until they
were detected, were so detrimental in our domain that we were not able
to seriously propose FF as a practical solution. Simple fixes to these
details are so effective that FF is now a practical (if not perfect)
possibility.



First, while pre-processing the ADL formulas, FF has a sub-routine
that checks the instantiated formulas -- quantifiers already compiled
into grounded conjunctions and disjunctions -- for tautologies. This
involves a loop checking all pairs of sub-formulas within every
conjunction and disjunction, testing whether they are
identical/identical modulo their sign. For example, if we find $\phi$
and $\neg \phi$ within a disjunction, then the disjunction is replaced
by TRUE. Now, we haven't tested thoroughly whether this sub-routine
has any notable effect on the formulas in other benchmarks. It
certainly has no such effect in our domain. The effect it {\em does}
have is take a huge amount of runtime on the long goal conjunctions
stating that we do not wish to have any open substitution nodes nor
any distractors. The simple fix is hence to switch this sub-routine
off. In small instances, this gives advantages like $0.29s$ vs.\ $11s$
pre-processing time; in a larger instance we ran, original FF's
pre-process doesn't finish within 15 minutes whereas our fix yields a
pre-processing time of about $3s$.


Second, FF's pre-process contains a very small imprudence that
apparently didn't surface in other domains, but that does in ours. FF
distinguishes operators into ``easy'' (DNF precondition) and ``hard''
(non-DNF precondition). The easy ones are instantiated in a
spezialized very effectively implemented procedure, while the hard
ones go through a much less effectively implemented more general
procedure. In particular, that latter procedure uses a data structure
encompassing an integer for every possible instantiation of all
predicates. Since this does not take into account reachability, it is
prohibitively huge in our domain. Now, there actually are no hard
operators in our domain. But FF builds the data structure anyway, even
though it is not needed. In small instances, this results in a couple
of seconds runtime overhead. In larger instances, it exhausts memory
and causes FF to terminate with a segmentation fault.




















\subsection{Search Techniques}
\label{sec:crisp-ff:preprocess:heuristics}





FF's pre-processing pitfalls -- and the fact that they didn't occur to
anyone before -- are certainly baffling, although easily fixed. We now
turn our attention to some of FF's search techniques, variations of
which are used in many planners and which are very much not easily
fixed.


%\item Goal agenda: For some reason that I don't understand in detail,
%  the goal agenda heuristic chooses that the ``subst'' goal must be
%  reached before even the ``expressed'' goal. This leads the planner
%  to generating some arbitrary sentence. Because the example grammar
%  is so small, this leads to a state from which the ``expressed'' goal
%  can no longer be achieved. (A realistic big grammar should be able
%  to recover from this by introducing a conjunction or relative clause
%  or some such -- but of course, this would still lead to a stupid
%  sentence.) FIX: turn goal agenda off. alternatively, develop
%  appropriate goal ordering techniques.


First, we consider Koehler and Hoffmann's
\shortcite{koehler:hoffmann:jair-00} ``reasonable goal orderings'',
variants and extensions of which are used in several planning systems
today, e.g.\ \cite{hoffmann:etal:jair-04,richter:etal:aaai-08}. FF as
used in the 2000 competition implements the ideas from
\cite{koehler:hoffmann:jair-00}, approximating reasonable orders as a
pre-process and then partitioning the goal set into a {\em goal
  agenda}, a sequence of goal subsets. Each subset is posed to the
planner in isolation, ignoring all other goals. The final plan is the
concatenation of the plans for all entries.

%EXAMPLE missing

While the goal agenda and related techniques have proved quite useful
in many domains, in the sentence generation domain they often are
completely off-target. The most striking point concerns the
interaction between the goal to create a sentence -- $\neg
\mathsf{subst}(S,\mathsf{root})$ in the rabbit example -- and the goal
to express a certain meaning -- $\mathsf{sleep}(e,r_1)$ in the
rabbit example. The goal agenda orders the former before the latter
because it detects that, once a meaning is expressed, the sentence
creation has started and it is not possible to start anew
anymore. Unless the inverse also holds,\footnote{The inverse holds if,
  in the given grammar, the only way to create a meaning is to create
  a full sentence -- i.e., there are no side sentences like ``the
  sleeping rabbit''.} $\mathsf{subst}(S,\mathsf{root})$ is alone in
the first goal agenda entry, i.e., there is no goal stating the actual
meaning the sentence is supposed to have. Consequently, the planner
decides to generate {\em any} sentence. If it happens to be the wrong
sentence, the planner is stuck in a dead-end. While that dead end is
recognized by the relaxed plan heuristic -- i.e., it is easy to see
that the actions needed for achieving the goal cannot be applied
anymore -- certainly this is an entirely unintended (and a bit
amusing) outcome of this technique. 
% Switching it off, we {\bf \dots
%example before/after.}


It is not clear to us, at this point, how goal ordering techniques
could be modified so that they return sensible results in the sentence
generation domain. The issue explained above regarding $\neg
\mathsf{subst}(S,\mathsf{root})$ and $\mathsf{sleep}(e,r_1)$ could be
addressed by recognizing that, once the latter is achieved, the former
is already true anyway. More generally however, the life-cycle of
substitution nodes and distractors is weird -- as we outline below, it
follows a false-true-false pattern -- and seems difficult to detect
based on domain analysis.










%\item Subst and distractor atoms have a weird lifecycle: They start as
%  false, then get made true at some point, and then false again.
%  After they have been made false, they can never become true
%  again. FIX: no fix just yet. highly non-trivial challenge to
%  generation of h fns. {\bf (QUESTION: does lama do better? do any of
%    the known admissible heuristics do better?)}


While the goal agenda meltdown may be more amusing than alarming, we
next report that relaxed plan heuristics are not far from such a
meltdown either. They are fatally confused by the weird lifecycle of
facts encoding substitution nodes and distractors. In instances where
these constructs are important for the construction of a valid
sentence, these facts are required to be false in the goal, and most
of them are initially false. However, any valid plan must make many of
them true at some intermediate time point (e.g.\ distractors arise
depending on the decisions taken by the planner). Hence, from the
perspective of the relaxed plan heuristic, from one state to the next
whole classes of goals suddenly appear ``out of the blue''. These
goals are not accounted for in the preceding state, and hence the
relaxed plan is completely un-informative.


Consider again the rabbit example. In the initial state, the relaxed
plan has length $1$ because we only need to achieve $\neg
\mathsf{subst}(S,\mathsf{root})$ and $\mathsf{sleep}(e,r_1)$, which is
done by the single action ``sleeps''. However, that action has the
effect ``forall (?y - individual) (when (not (= ?y ?xself))
(distractor ?subjnode ?y))'' which introduces new distractors. Those
must be removed, so they form ``new'' goals. In the given case, the
relaxed plan now contains two actions to achieve these goals. In
general (if there are $n$ rabbits, say), the relaxed plan may become
arbitrarily long.
%To give just one concrete example, say we are in the initial state,
%and have not yet committed to a sentence. For certain kinds of
%sentences ({\bf more concrete here???}), the relaxed plan has length
%$1$ because the we only need to choose the desired meaning. However,
%in the state $s$ resulting from this action, the mechanisms of the
%planning task introduce all the sub-goals that are required in order
%to pin-point that meaning (in particular we get a new goal for all the
%distractors that must be removed). Hence the relaxed plan is much
%longer than before -- arbitrarily longer, in general.  
For FF's particular search algorithm, enforced hill-climbing (EHC),
this means that {\em FF performs a blind breadth-first search}: EHC
starts at $h$ value $1$ and thereafter needs to solve the whole
problem in order to find a (goal) state with lower $h$ value.

%../ff -o modifiers-10-10-domain.lisp -f modifiers-10-10-problem.lisp -T -H

%\item As a consequence, Enforced hillclimbing: Initial state of
%  example problem has a relaxed graph of length one because
%  ``expressed'' and ``subst'' goals are achieved, and newly introduced
%  violations of ``subst'' and ``distractor'' are not noticed. As a
%  consequence, EHC on the second state spends all of its time in
%  breadth-first search. FIX: don't use EHC.


More generally, from this example we immediately see that, in the
terms of Hoffmann \shortcite{hoffmann:jair-05}, the exit distance from
local minima under $h^+$ is unbounded. Also, we have unrecognized
dead-ends, i.e., dead-end states that have a relaxed plan. An example
is the initial state of a task that features distractors for which
there is no means of removal -- ignoring the distractors, the initial
$h$ value will still be $1$. So our domain is in the most difficult
class of Hoffmann's \shortcite{hoffmann:jair-05} ``planning domain
taxonomy''. While it shares this property with several other
challenging domains, the extremity of turning EHC into a breadth-first
search is unheard of.


Can we design heuristics that are better at deadling with the
lifecycle of substitution nodes and distractors? The problem of not
noticing them in the initial state is present for all approaches that
are dominated by $h^+$,
e.g.\ \cite{karpas:domshlak-ijcai-09,helmert:domshlak:icaps-09}, and
is also present for the known inadmissible landmarks heuristics
\cite{richter:etal:aaai-08}. As far as known heuristics are concerned,
hope thus resides mainly in the $h^m$ family and in abstraction
heuristics. We ran a few tests with an example like the rabbit one,
except that there are 10 distractors. The Graphplan estimate for the
initial state is $4$, i.e., $h^2$ is better than $h^+$ here. Still,
$4$ is far away from the real goal distance $14$. With merge\&shrink
\cite{helmert:etal:icaps07}, {\bf \dots (malte agreed to run a test on
  modifiers-10-10-)}






The only FF technique that appears to work reasonably well is its
action pruning technique, the ``helpful actions''. While the relaxed
plan is often much too short, it appears to always contain at least
one of the actions that actually are useful, and it certainly prunes
the set of avaibale actions quite effectively. For example, in one of
the instances where EHC turns into a breadth-first search, $16875$
nodes are explored without helpful actions; with helpful actions, this
reduces to $3078$. For larger examples, the factor between the two
numbers tends to become larger. 
%{\bf use here larger version of
%  modifiers-10-10???}



Since EHC is often completely inadequate, and helpful actions are
quite effective, our FF configuration directly runs best-first search
with helpful actions (as opposed to original FF which switches to
best-first with{\em out} helpful actions if EHC fails).


%\item The only thing that works well is helpful actions. However,
%  these didn't get around to be used due to no helpful actions in
%  best-first search: After failure of EHC, FF falls back to best-first
%  search, but doesn't use the helpful actions heuristic in this
%  search. FIX: simply go straight to BFS with helpful actions.








%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
