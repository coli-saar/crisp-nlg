\section{Related Work}
\label{sec:related}
Statistical methods are extremely popular for surface realization, but have not been used in systems that integrate sentence planning. Most statistical generation approaches follow a generate-and-select strategy, first proposed by \newcite{knight1995} in their {\sc nitrogen} system. Such systems generate a set of candidate sentences using a conventional (non-statistical) grammar and then select the best output sentence by applying a statistical language model. This family includes systems such as {\sc HAL}ogen \cite{langkildeknight1998,langkilde2000} and open{\sc CCG} \cite{whitebaldridge2003}.  The {\sc fergus} system by \newcite{bangalorerambow2000} is a variant of this approach that, like {\sc pcrisp}, employs {\sc ltag}. It first assigns elementary trees to each entity in the input sentence plan using a statistical tree model and then computes the most likely derivation using using only these trees with an $n$-gram model on the output sentence. An alternative to the generate and select approach is to use a probabilistic grammar model, like {\sc ptag}, trained on automatic parses \cite{zhongstent2005}. A related approach uses a model over local decisions of the generation system itself \cite{belz2008}. Both model can either be used to discriminate a set of output candidates, or more directly to choose the next best decision locally. Our approach is similar, because it uses {\sc ptag} to find the most likely output structure. However, the previous work discussed so far addresses surface realization only.
The generate and select approach is even incompatible with the integrated treatment of sentence planning and realization, because it discriminates between possible linearization of the same lexical material. In contrast, {\sc pcrisp} addresses sentence planning as well.

Our treatment of integrated sentence planning and surface realization as planning, is inherited directly from {\sc crisp} \cite{kollerstone2007}.  Planning has long played a role in generation, but has focused on discourse planning instead of specifically addressing sentence generation \cite{hovy1988,appelt1992}. The applicability of these ideas was limited at that time because efficient planning technology was not available. Recently the development of more efficient planning algorithms (e.g. \newcite{hoffmannnebel2001,richterwestphal2008}) spawned a renewed interest in planning for NLG.  
{\sc Crisp} uses such efficient algorithms to efficiently solve the sentence generation problem defined by {\sc spud} \cite{stonedoran1997}. {\sc Spud}, which instead used an incomplete greedy algorithm, is based on an {\sc ltag} whose trees are augmented with semantic and pragmatic constraints. Given a communicative goal, a solution to the {\sc spud} problem realizes this goal and simultaneously selects referring expressions. The next section explores this idea in more detail.
