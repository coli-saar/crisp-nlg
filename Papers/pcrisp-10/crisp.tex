\section{Sentence Generation as Planning}
\label{sec:crisp}
In this section we review the original non-statistical {\sc crisp} system \cite{kollerstone2007}. 
Following {\sc spud} \cite{stonedoran1997}, {\sc crisp} is based on a declarative description of the sentence generation problem using {\sc tag}. Given a knowledge base, a communicative goal and a grammar, we require to find a grammatical {\sc tag} derivation that is consistent with this knowledge base and satisfies a communicative goal. A number of semantic and pragmatic constraints that must be satisfied by the solution can be added, for instance to enforce generation of unambiguous refering expressions. \newcite{kollerstone2007} describe how to encode this problem into an AI planning problem, that can be solved efficiently by off-the-shelf planners. We describe the general mechanism in the following section and then review the encoding into planning in section \ref{ssec:crispdomain}. 
\begin{figure*}[th]
\begin{center}
\includegraphics[width=.8\textwidth]{figures/grammar.pdf}
\caption{\label{fig:grammar}(a) An example grammar with semantic content. (b) A derivation for ``the cat eats raw tuna''. }
\end{center}
\end{figure*}

\subsection{Sentence Generation in CRISP}
Like {\sc spud}, {\sc crisp} uses an {\sc ltag} in which elementary trees are assigned semantic content. Each node in a {\sc crisp} elementary tree node is associated with a semantic role. Semantic content is expressed as a set of literals, encoding relations between these roles. All nodes that dominate the lexical anchor are assigned the role `self', which intuitively corresponds to the event or individual described by this tree. Figure \ref{fig:grammar}(a) shows an example grammar of this type. 

In a derivation we may only include elementary trees whose semantic content has an instantiation in the knowledge base. For each substitution and adjunction, the semantic role associated with the role of the target node is unified with the `self' role of the child tree. For example, given the knowledge base 
{\it \{cat($i_2$), tuna($i_3$), raw($i_3$), eats($i_1$,$i_2$,$i_3$)\}} and the grammar in \ref{fig:grammar}(a), {\sc crisp} could produce the derivation in \ref{fig:grammar}(b).


\subsection{CRISP Planning Domains} 
\label{ssec:crispdomain}
Before we describe {\sc crisp}'s encoding of sentence generation as planning, we briefly review AI planning in general. 
The crucial concept in AI planning is a state, a conjunction of first order literals describing relations between some individuals. A planning problem consist of an initial state, a set of goal states and a set of planning operators that describe possible state transitions.  A solution to the problem is any sequence of actions (instantiated operators) that leads from the initial state to one of the goal states. Planning problems can be written in a standard notation ({\sc pddl}\footnote{Planning Domain Description Language}, \newcite{gerevinietal2009}) and can be solved efficiently by planning systems such as {\sc ff}\footnote{Fast Forward} \cite{hoffmannnebel2001}.  
     
In {\sc crisp} planning states correspond to partial {\sc tag} derivations and record open substitution and adjunction sites, semantic individuals associated with them, and parts of the communicative goal that have not yet been expressed.  The initial state also encodes the knowledge base and the communicative goal. Each planning operator contributes a new elementary tree to the derivation and at the same time satisfies part of the communicative goal, as described in the previous section. In a goal state there are no open substitution sites left and all literals in the communicative goal have been expressed. 
\begin{figure}[t]
\begin{center}
\planaction{\bf S-eats-1(u,~x1,~x2,~x3)}{step(step1),referent(u,~x1),\\ subst(S,~u), eats(x1,~x2,~x3)}{
$\lnot$needtoexpr(pred-eats,~x1,~x2,~x3),\\ $\lnot$subst(S,~u),\\
subst(NP,~subj-1), subst(NP,~obj-1),\\ refer(subj-1,~x2), refer(obj-1,~x3)\\
canadj(VP, u), canadj(V, u), canadj(S, u)\\
$\lnot$ step(step1), step(step2)}\\\smallskip

\planaction{\bf NP-cat-2(u,~x1)}{step(step1),referent(u,~x1),\\ subst(NP,~u), cat(x1)}{
$\lnot$needtoexpress(pred-cat,~x1),\\ $\lnot$subst(NP,~u),\\
canadj(N, u), canadj(NP, u)\\
$\lnot$ step(step1), step(step2)}\\\smallskip

\planaction{\bf N-raw-4(u,~x1)}{step(step1),referent(u,~x1),\\ canadj(N,~u), raw(x1)}{
$\lnot$needtoexpress(pred-raw,~x1),\\ $\lnot$canadj(N,~u),\\
$\lnot$ step(step4), step(step5)}\\\smallskip
\end{center}
\caption{\label{fig:crisp-operators} {\sc crisp} operators for some of the elementary trees in figure \ref{fig:grammar}.}
\end{figure}


Figure \ref{fig:crisp-operators} shows planning operators for part of the grammar in figure \ref{fig:grammar}(a).
The preconditions of the operators require that a suitable open substitution node (i.e. of the correct category) or internal node for adjunction exists in the partial derivation. In the operator effect, open substitution nodes are closed and new identifiers are created for each substitution node and internal node in the new tree. Given the knowlede base from above, a plan corresponding to the derivation in figure \ref{fig:grammar} would be $\langle${\it S-eats-1(root, i1, i2, i3), NP-cat-2(subj-1, i2), NP-tuna-3(obj-1, i3), N-raw-4(obj-1, i3)}$\rangle$

\subsection{CRISP and Large Grammars}
Trees in large, possibly treebank induced grammars are often applicable in a number of different syntactic contexts, leading to overgeneration. Such trees contain many internal nodes that are open for adjunction but will not necessarily be filled in a derivation for a given input communicative goal. Attaching to the wrong node can produce invalid or disprefered word order. 
In addition, in such grammars the ambiguity of possible, structurally different trees (supertags) for a given word is high. These problems are illustrated in figure \ref{fig:overgen}. Assuming a grammar that includes trees for both right attaching ($t13$) and left attaching PPs ($t252$), both derivations (a) and (b) are {\it grammatical} derivations that satisfy the same communicative goal. However, most readers disprefer the reading in (b). 
Clearly, to use {\sc crisp} with such a grammar we need a method of distinguishing good derivations from bad ones. 
\begin{figure*}
\begin{center}
\includegraphics[width=.6\textwidth]{figures/overgen.pdf}
\caption{\label{fig:overgen} Two derivations with a large grammar, that satisfy the same communicative goal. Sentence (b) is disprefered by most readers.}
\end{center}
\end{figure*} 

