\section{Introduction} \label{sec:intro}

Representing semantics as a logical form that supports automated
inference and model construction is vital for deeper language
engineering tasks, such as dialogue systems.  Logical forms
can be obtained from hand-crafted deep grammars
\cite{butt:etal:1999,copestake:flickinger:2000}, but this
tends to lack robustness: hand-crafted grammars fail to cover all
words and linguistic constructions and by design they do not handle
ill-formed phrases. 

On the other hand, there has been a recent trend towards systems for
robust wide-coverage semantic construction.  For instance,
\newcite{bos:etal:2004} exploit {\sc ccg}'s elegant syntax-semantics
interface to produce a unique logical form for each derivation of a
statistical {\sc ccg} parser; \newcite{zettlemoyer:collins:2007} and
others learn string-to-logical-form mappings, exploting informative
features from shallow language processors; and
\newcite{copestake:2003} and \newcite{frank:2004} endow robust
language processors with semantic components.

% COMMENT: this issue about optional arguments is really too cryptic.
% Basically, there is no way for assessing by *any* learned language
% processor whether a single word form that appears in
% a number of different syntactic valencies is an example of lexical
% sense ambiguity, or they are all examples of the same sense being
% used in syntactically different ways (i.e., we have optional
% arguments).  Only hand-crafted grammars can tell you this.  So, for
% example, Bos et al (2004) would get bet(x,y) for "I bet 5 pounds",
% and bet(x,y,z) for "I bet you 5 pounds" and bet(x,p) for "I bet it's
% going to rain": I.e., the vocab of the semantic formalism is
% constructed automatically from NL word forms, and the predicate
% symbols in that automatically constructed vocab vary in (a) valency,
% and (b) the semantic dependencies represented by a given argument
% position (e.g., the second argument of "bet" in "I bet 5 pounds" is
% 5 pounds, and for "I bet it's raining" it's "it's raining".
% 

However, there are certain semantic phenomena that these robust
approaches don't capture reliably, including quantifier scope,
optional arguments, and long-distance dependencies (for instance,
\newcite{clark:etal:2004} report that the parser used by
\newcite{bos:etal:2004} yields only 63\% accuracy on object
extraction; e.g., {\em the man that I met\dots}).  Forcing a shallow
parser to make a decision about these phenomena can therefore be
error-prone.  Depending on the application, it may be preferrable to
give the parser the option to to leave the decision open when it's not
sufficiently informed---i.e., to compute a partial semantic
representation that neither over-determines nor under-determines the
semantic information revealed by the (shallow) syntactic analysis, and
to complete the semantic information later, using information
extraneous to the parser.

In this paper, we focus on one particular approach to representing
partial semantic information: Robust Minimal Recursion Semantics
(\rmrs, \cite{copestake:2003}).  \rmrs\ is a generalisation of \mrs\
\cite{copestake:etal:2005} that is designed to support
underspecification of scope and predicate-argument structure.  It is
an emerging standard representation language for partial semantic
information, and has been applied in several implemented systems.  For
instance, \newcite{copestake:2003} and \newcite{frank:2004} use it to
specify semantic components to shallow parsers ranging in depth from
{\sc pos} taggers to chunk parsers and intermediate parsers such as
{\sc rasp} \cite{briscoe:etal:2006}.  {\sc mrs} analyses derived from
deep grammars, such as the English Resource Grammar ({\sc erg},
\cite{copestake:flickinger:2000}) can be seen as special cases of {\sc
  rmrs}.

However, from a formal perspective, \rmrs\ is somewhat ad-hoc in that
it has no clearly defined model theory; i.e., it is not defined what,
exactly, any given \rmrs\ representation actually \emph{means}.  The
key contribution we make is to cast {\sc rmrs}, for the first time, as
a logic with a well-defined model theory.  This has a number of
advantages.  First, it allows us to formally relate \rmrs\ to other
frameworks such as \mrs\ and predicate logic in order to establish the
compatibility of \rmrs\ with the approaches to robust semantic
analysis mentioned above.  \todo{except we don't do this here --
  perhaps we should} Second, it provides us with a notion of logical
entailment, which we can use to verify the compatibility of \rmrs\
representations computed from different parsers, such as a deep and a
shallow parser.  Finally, it is only through rigid formalisation that
we can give users of \rmrs\ access to inference systems and to
algorithms for efficiently computing the possible fully specific
semantic representations described by the \rmrs\ output of a shallow
parser.

Section~\ref{sec:motivation} illustrates via example the differences
and challenges with deep and shallow semantic construction.
Section~\ref{sec:rmrs} defines the syntax and model-theory of \rmrs\.
In Section~\ref{sec:entailment} we demonstrate the practical
usefulness of our formalisation by modelling compatibility of partial
semantic representations as \rmrs\ entailment and by providing a
syntactic criterion for characterising entailment.
Section~\ref{sec:conclusion} concludes and points to future work.


\hidden{
The language in which these partial representations are expressed 


Moreover, in a hybrid system that attempts to combine the outputs of
deep and shallow parsers, 



Robost language processors that produce a single conventional logical
form for a given natural language string are beginning to emerge
(e.g.,
\cite{bos:etal:2004,rupp:etal:2000,wong:mooney:2006,zettlemoyer:collins:2005}).
But the output of these systems don't relate to any gold standard deep
parse as produced by expert grammar developers (for instance, while
the training corpus used in \cite{zettlemoyer:collins:2005} features
control phenomena in the language strings, their logical forms don't
represent it).  This makes it hard to judge the logical forms that the
models derive from a linguistic perspective; nor can one integrate
their output with that of a hand-crafted grammar when desired.




This paper focuses on a particular approach to producing partial
semantic information from robust parsers, exemplified in
\cite{copestake:2003,frank:2004}, among others.  Their strategy is to
utilise semantic underspecification to semi-automatically build
semantic components to shallow parsers, so that the output neither
over-determines nor under-determines the semantic information that is
revealed by the (shallow) syntactic analysis.  The semantic formalism
used to express this is Robust Minimal Recursion Semantics

; this is a generalisation of 

 that is designed to be maximally flexible
in the type of semantic information that can be left underspecified:
it can express partial information about semantic scope, the values of
arguments to predicate symbols and/or their argument position, the
arity of the predicate symbols and the sorts of arguments they take.
We show in Section~\ref{sec:motivation} that all these features are
needed when information about lexical subcategorisation or syntactic
dependencies is missing---a characteristic feature of shallow parsers.
Several researchers have demonstrated that {\sc rmrs} is a suitable
framework on which to semi-automatically construct semantic components
to shallow parsers, ranging in depth .






A major motivation for adopting {\sc rmrs} over other techniques for
robustly deriving logical forms is the promise that it can form the
basis for integrating the output of several parsers, and be compared
in particular with the output of a hand-crafted grammar.  This paper
demonstrates the feasibility of this integration for the first time,
by introducing a model theory for {\sc rmrs}, that in turn defines
entailment among {\sc rmrs} representations.  This entailment relation
is also characterised syntactically as an extension of solved forms
(ref to solved forms).  We show that the proof theory and model theory
of {\sc rmrs} that results provides a formal basis for integrating the
semantic output of several shallow parsers, for checking the
satisfiability of a shallow parse, and for testing its compatibility
with a deep parse.


}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rmrs-08"
%%% End: 
