\section{Introduction} \label{sec:intro}

Representing semantics as a logical form that supports automated
inference and model construction is vital for deeper language
engineering tasks, such as dialogue systems.  Such detailed semantic
representations can be obtained from hand-crafted deep grammars (e.g.,
\cite{butt:etal:1999,copestake:flickinger:2000}), but deep parsing
tends to lack robustness: hand-crafted grammars fail to cover all
words and linguistic constructions; and unedited text and speech
contains ill-formed phrases, which by design deep grammars do not
handle.

On the other hand, there has been a recent trend towards systems for
robust wide-coverage semantic construction.  For instance,
\cite{bos:etal:2004} exploit
{\sc ccg}'s elegant syntax-semantics interface to produce a unique
logical form for each derivation of
a statistical {\sc ccg} parser;
\cite{zettlemoyer:collins:2007} and others learn
string-to-logical-form mappings, exploting informative features from
the output of
shallow language processors; and \cite{copestake:2003} and
\cite{frank:2004}, among others,
endow robust language processors with semantic components.

However, there are certain semantic
phenomena that such shallow
approaches can't capture reliably, including quantifier scope, optional
arguments,
% COMMENT: this issue about optional arguments is really too cryptic.
% Basically, there is no way for assessing by *any* learned language
% processor whether a single word form that appears in
% a number of different syntactic valencies is an example of lexical
% sense ambiguity, or they are all examples of the same sense being
% used in syntactically different ways (i.e., we have optional
% arguments).  Only hand-crafted grammars can tell you this.  So, for
% example, Bos et al (2004) would get bet(x,y) for "I bet 5 pounds",
% and bet(x,y,z) for "I bet you 5 pounds" and bet(x,p) for "I bet it's
% going to rain": I.e., the vocab of the semantic formalism is
% constructed automatically from NL word forms, and the predicate
% symbols in that automatically constructed vocab vary in (a) valency,
% and (b) the semantic dependencies represented by a given argument
% position (e.g., the second argument of "bet" in "I bet 5 pounds" is
% 5 pounds, and for "I bet it's raining" it's "it's raining".
% 
and long-distance dependencies.  
% TODO: search Steedman and Clark EMNLP 2004 for the performance
% figures on object relative clauses (which is constructions like
% "The man that I met", "the man that I think likes me", but not "the
% man that likes me"; they get about 50% of them exactly right; this
% is impressive but shows it's error prone.
Forcing a shallow parser
to make a decision about these phenomena therefore can be a major source
of errors.  It would be preferrable to give the parser the option to
declare itself not sufficiently informed to make the decision, and
to leave the decision open -- i.e., to compute a partial semantic
representation that neither over-determines nor under-determines the
semantic information revealed by the (shallow) syntactic analysis, and
to complete the semantic information later, via inferences that
exploit information extraneous to the shallow parser.

In this paper, we focus on one particular approach to representing
partial semantic information:
Robust Minimal Recursion Semantics ({\sc rmrs},
\cite{copestake:2003}).  {\sc rmrs} is a generalisation of {\sc mrs}
\cite{copestake:etal:2005}, designed to support underspecification both
of scope relations and of the predicate-argument structure.
\cite{copestake:2003, frank:2004} use it to
support semantic constructions by shallow parsers
ranging in depth from {\sc pos} taggers to chunk parsers  
and intermediate parsers such as {\sc rasp}
\cite{briscoe:etal:2006}.  {\sc mrs} analyses
derived from deep grammars, such as the English Resource Grammar
\cite{copestake:flickinger:2000} can also be seen as special cases of
{\sc rmrs} representations.

The key contribution we make is to cast {\sc rmrs}, for the first
time, as a logic with a clearly defined model theory.  This has a
number of advantages.  First, it allows us to formally relate \rmrs\ to
other framework such as \mrs\ and predicate logic in order to
establish the compatibility of \rmrs\ with the approaches to robust
semantic analysis mentioned above.  Second, it provides us with a
notion of logical entailment, which we can use to verify the
compatibility of \rmrs\ representations computed from different
parsers, such as a deep and a shallow parser.  Finally, it is only
through rigid formalisation that we can give users of \rmrs\ access to
inference systems and to algorithms for efficiently computing the
possible fully specific semantic representations described by a
partial \rmrs.

We will first illustrate the differences and challenges with deep and
shallow semantic construction in an example in
Section~\ref{sec:motivation}.  We will then define the syntax and
model-theoretic semantics of \rmrs\ and introduce some important
formal concepts in Section~\ref{sec:rmrs}.  Finally, we demonstrate
the practical usefulness of our formalisation in
Section~\ref{sec:entailment} by modelling compatibility of
partial semantic representations as \rmrs\ entailment and providing a
syntactic criterion for characterising entailment.
Section~\ref{sec:conclusion} concludes and points to future work.


\hidden{



The language in which these partial representations are expressed 


Moreover, in a hybrid system that attempts to combine the outputs of
deep and shallow parsers, 



Robost language processors that produce a single conventional logical
form for a given natural language string are beginning to emerge
(e.g.,
\cite{bos:etal:2004,rupp:etal:2000,wong:mooney:2006,zettlemoyer:collins:2005}).
But the output of these systems don't relate to any gold standard deep
parse as produced by expert grammar developers (for instance, while
the training corpus used in \cite{zettlemoyer:collins:2005} features
control phenomena in the language strings, their logical forms don't
represent it).  This makes it hard to judge the logical forms that the
models derive from a linguistic perspective; nor can one integrate
their output with that of a hand-crafted grammar when desired.




This paper focuses on a particular approach to producing partial
semantic information from robust parsers, exemplified in
\cite{copestake:2003,frank:2004}, among others.  Their strategy is to
utilise semantic underspecification to semi-automatically build
semantic components to shallow parsers, so that the output neither
over-determines nor under-determines the semantic information that is
revealed by the (shallow) syntactic analysis.  The semantic formalism
used to express this is Robust Minimal Recursion Semantics

; this is a generalisation of 

 that is designed to be maximally flexible
in the type of semantic information that can be left underspecified:
it can express partial information about semantic scope, the values of
arguments to predicate symbols and/or their argument position, the
arity of the predicate symbols and the sorts of arguments they take.
We show in Section~\ref{sec:motivation} that all these features are
needed when information about lexical subcategorisation or syntactic
dependencies is missing---a characteristic feature of shallow parsers.
Several researchers have demonstrated that {\sc rmrs} is a suitable
framework on which to semi-automatically construct semantic components
to shallow parsers, ranging in depth .






A major motivation for adopting {\sc rmrs} over other techniques for
robustly deriving logical forms is the promise that it can form the
basis for integrating the output of several parsers, and be compared
in particular with the output of a hand-crafted grammar.  This paper
demonstrates the feasibility of this integration for the first time,
by introducing a model theory for {\sc rmrs}, that in turn defines
entailment among {\sc rmrs} representations.  This entailment relation
is also characterised syntactically as an extension of solved forms
(ref to solved forms).  We show that the proof theory and model theory
of {\sc rmrs} that results provides a formal basis for integrating the
semantic output of several shallow parsers, for checking the
satisfiability of a shallow parse, and for testing its compatibility
with a deep parse.


}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rmrs-08"
%%% End: 
